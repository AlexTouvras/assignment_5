{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5\n",
    "\n",
    "![image info](https://www.mdpi.com/sensors/sensors-17-01951/article_deploy/html/images/sensors-17-01951-g003.png)\n",
    "\n",
    "\n",
    ">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\n",
    "(https://arxiv.org/abs/1602.07360)\n",
    "\n",
    "In this assigment you're going to use the pretrained network SqueezeNetv1.2 (~ 5 Mb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (5 points):\n",
    "\n",
    "go to https://github.com/miaow1988/SqueezeNet_v1.2 and download the 'symbol.json' and '.params' files (there is not a 'synset.txt' file! so don't use these lines, Hint: just comment these lines).\n",
    "\n",
    "* Install MXNet v1.5 (hint: create a new conda environmet with python 3, pip install mxnet==1.5.1) and follow the same steps of the lecture (part: *Using pre-trained models as feature extractors*). Find the flatten output layer and create a feature extractor (hint: It should be a numpy array of 1000 elements).\n",
    "* Download the dogs versus cats *training folder* from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data (Remember the number of images is 12500 for each class).\n",
    "* Extract the array of features for different number of images (N: 10, 100, 500, 1000, also 5000 and 12500) and for each value train your favorite binary classifier (only one!!!) using GridSearch to optimize some hyperparameters. Consider to use https://notebooks.csc.fi if you have computational limitations. \n",
    "\n",
    "* Report the accuracy for each value of N and the computational time during the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet==1.5.1\n",
      "  Downloading mxnet-1.5.1-py2.py3-none-manylinux1_x86_64.whl (23.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.1 MB 3.6 MB/s eta 0:00:01                    | 1.5 MB 3.6 MB/s eta 0:00:06  | 2.5 MB 3.6 MB/s eta 0:00:06██████▏                         | 4.5 MB 3.6 MB/s eta 0:00:06 3.6 MB/s eta 0:00:05                  | 8.2 MB 3.6 MB/s eta 0:00:054��▉                | 11.5 MB 3.6 MB/s eta 0:00:04�██████████████▌             | 13.4 MB 3.6 MB/s eta 0:00:03�██████▏          | 15.3 MB 3.6 MB/s eta 0:00:03███████████████████▏        | 16.7 MB 3.6 MB/s eta 0:00:02��█▎      | 18.2 MB 3.6 MB/s eta 0:00:02��███▊    | 20.1 MB 3.6 MB/s eta 0:00:01█████▌  | 21.3 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.7/site-packages (from mxnet==1.5.1) (1.18.2)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from mxnet==1.5.1) (2.23.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (1.25.7)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "  Attempting uninstall: graphviz\n",
      "    Found existing installation: graphviz 0.13.2\n",
      "    Uninstalling graphviz-0.13.2:\n",
      "      Successfully uninstalled graphviz-0.13.2\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install mxnet==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-symbol.json', 'model-0000.params']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "path='https://github.com/miaow1988/SqueezeNet_v1.2'\n",
    "[mx.test_utils.download(path+'blob/master/model-symbol.json'),\n",
    " mx.test_utils.download(path+'blob/master/model-0000.params')]\n",
    " #mx.test_utils.download(path+'synset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('model', 0)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "# with open('synset.txt', 'r') as f:\n",
    "#    labels = [l.rstrip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire9_concat_output',\n",
       " 'dropout0_output',\n",
       " 'conv10_conv_weight',\n",
       " 'conv10_conv_bias',\n",
       " 'conv10_conv_output',\n",
       " 'conv10_relu_output',\n",
       " 'pool10_output',\n",
       " 'flatten0_output',\n",
       " 'softmax_label',\n",
       " 'softmax_output']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the last 10 layers\n",
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['flatten0_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img):\n",
    "    fe_mod.forward(Batch([mx.nd.array(img)]))\n",
    "    features = fe_mod.get_outputs()[0].asnumpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.23.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.1)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (47.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.6 MB 24.4 MB/s eta 0:00:01                            | 1.4 MB 3.9 MB/s eta 0:00:12█▉                              | 2.8 MB 3.9 MB/s eta 0:00:12                         | 5.3 MB 3.9 MB/s eta 0:00:118 MB 3.9 MB/s eta 0:00:11███▋                          | 8.4 MB 3.9 MB/s eta 0:00:10 MB 3.9 MB/s eta 0:00:10                      | 13.6 MB 3.9 MB/s eta 0:00:09 MB 3.9 MB/s eta 0:00:09MB/s eta 0:00:08██████████                    | 17.7 MB 3.9 MB/s eta 0:00:08�████████▏                  | 19.6 MB 3.9 MB/s eta 0:00:08          | 21.3 MB 3.9 MB/s eta 0:00:07��█████████▏                | 22.5 MB 3.9 MB/s eta 0:00:07 MB 3.9 MB/s eta 0:00:06��███████████▌              | 26.0 MB 3.9 MB/s eta 0:00:06MB/s eta 0:00:06   | 28.7 MB 24.4 MB/s eta 0:00:01    | 31.5 MB 24.4 MB/s eta 0:00:01B 24.4 MB/s eta 0:00:01��█████████████████████▉        | 35.5 MB 24.4 MB/s eta 0:00:01████████████████       | 37.3 MB 24.4 MB/s eta 0:00:01 | 39.2 MB 24.4 MB/s eta 0:00:01███████▌    | 40.9 MB 24.4 MB/s eta 0:00:01��███████████████████▊   | 42.8 MB 24.4 MB/s eta 0:00:01███████████████▉  | 44.3 MB 24.4 MB/s eta 0:00:01 MB 24.4 MB/s eta 0:00:01��█████████████████████████▉| 47.4 MB 24.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.25.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.4.58\n"
     ]
    }
   ],
   "source": [
    "! pip install requests matplotlib opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "# define a simple data batch\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(url, show=False):\n",
    "    if url.startswith('http'):\n",
    "        # download and show the image\n",
    "        fname = mx.test_utils.download(url)\n",
    "    else:\n",
    "        fname = url\n",
    "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "         return None\n",
    "    if show:\n",
    "         plt.imshow(img)\n",
    "         plt.axis('off')\n",
    "    # convert into format (batch, RGB, width, height)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2)\n",
    "    img = img[np.newaxis, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /opt/conda/lib/python3.7/site-packages (0.1.20)\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (from opendatasets) (1.5.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from opendatasets) (4.43.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from opendatasets) (8.0.3)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.23.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2019.11.28)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.8.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.25.7)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from click->opendatasets) (1.5.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (2.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->opendatasets) (3.1.0)\n",
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: alextouvras\n",
      "Your Kaggle Key: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1.00M/814M [00:00<02:18, 6.15MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dogs-vs-cats-redux-kernels-edition.zip to ./dogs-vs-cats-redux-kernels-edition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814M/814M [00:21<00:00, 39.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting archive ./dogs-vs-cats-redux-kernels-edition/dogs-vs-cats-redux-kernels-edition.zip to ./dogs-vs-cats-redux-kernels-edition\n"
     ]
    }
   ],
   "source": [
    "! pip install opendatasets\n",
    "import opendatasets as od\n",
    "import zipfile as zf\n",
    "od.download(\"https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\")\n",
    "\n",
    "\n",
    "files = zf.ZipFile(\"dogs-vs-cats-redux-kernels-edition/train.zip\", 'r')\n",
    "files.extractall('images')\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "mypath = join(os.getcwd(),'images/train')\n",
    "\n",
    "cats_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('cat')]\n",
    "dogs_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('dog')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats: 12500 and dogs: 12500\n"
     ]
    }
   ],
   "source": [
    "print(\"cats: {} and dogs: {}\".format(len(cats_imgs),len(dogs_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features of all 12500 cats and 12500 dogs this might take a while\n",
    "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs]\n",
    "dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training took 0.13 seconds for 10 images\n",
      "Best cross-validation score: 0.93\n",
      "Test set score: 1.00\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 2, 'svc__gamma': 0.001}\n",
      "\n",
      "Model training took 0.92 seconds for 100 images\n",
      "Best cross-validation score: 0.96\n",
      "Test set score: 0.94\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 1, 'svc__gamma': 0.01}\n",
      "\n",
      "Model training took 12.23 seconds for 500 images\n",
      "Best cross-validation score: 0.97\n",
      "Test set score: 0.94\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 5, 'svc__gamma': 0.01}\n",
      "\n",
      "Model training took 41.14 seconds for 1000 images\n",
      "Best cross-validation score: 0.95\n",
      "Test set score: 0.95\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 10, 'svc__gamma': 0.001}\n",
      "\n",
      "Model training took 631.00 seconds for 5000 images\n",
      "Best cross-validation score: 0.97\n",
      "Test set score: 0.96\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n",
      "Model training took 3385.21 seconds for 12500 images\n",
      "Best cross-validation score: 0.97\n",
      "Test set score: 0.97\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "Nmax_values = [10, 100, 500, 1000, 5000, 12500]\n",
    "\n",
    "pipe = Pipeline([('Preprocessing', MinMaxScaler()), ('svc', SVC())])\n",
    "\n",
    "param_grid = {'Preprocessing': [MinMaxScaler()],\n",
    "              'svc__C': [1, 2, 5, 10],\n",
    "              'svc__gamma':[0.0001, 0.001, 0.01, 0.1]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=3)\n",
    "\n",
    "for Nmax in Nmax_values:\n",
    "    \n",
    "    Y_cats = np.array(Nmax * [1])\n",
    "    Y_dogs = np.array(Nmax * [0])\n",
    "    X_cvd = np.vstack([cats_features[:Nmax],dogs_features[:Nmax]])\n",
    "    Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "    start = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "   \n",
    "    print(\"Model training took %.2f seconds for %d images\"\n",
    "      % ((time() - start), Nmax))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "    print(\"Best parameters: {}\\n\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 (5 points):\n",
    "\n",
    "Repeat all previous steps using MobileNet V2 (https://github.com/KeyKy/mobilenet-mxnet). How the two networks compare in terms of accuracy and running time?\n",
    "\n",
    "**WARNING**: At least for N= 5000 and 12500 it can take some time in your computer, depending of your resources. The time can largely increases depending of your chosen classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mobilenet_v2-symbol.json', 'mobilenet_v2-0000.params']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "path='https://github.com/KeyKy/mobilenet-mxnet'\n",
    "[mx.test_utils.download(path+'blob/master/mobilenet_v2-symbol.json'),\n",
    " mx.test_utils.download(path+'blob/master/mobilenet_v2-0000.params')]\n",
    " #mx.test_utils.download(path+'synset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('mobilenet_v2', 0)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "# with open('synset.txt', 'r') as f:\n",
    "#    labels = [l.rstrip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv6_4_bn_moving_var',\n",
       " 'conv6_4_bn_output',\n",
       " 'relu6_4_output',\n",
       " 'pool6_output',\n",
       " 'fc7_weight',\n",
       " 'fc7_bias',\n",
       " 'fc7_output',\n",
       " 'fc7_flatten_output',\n",
       " 'prob_label',\n",
       " 'prob_output']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the last 10 layers\n",
    "all_layers = sym.get_internals()\n",
    "all_layers.list_outputs()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['fc7_flatten_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features this might take a while\n",
    "cats_features_2 = [get_features(get_image(img)).ravel() for img in cats_imgs[:1000]] # reading features for the first 1000 pics only\n",
    "dogs_features_2 = [get_features(get_image(img)).ravel() for img in dogs_imgs[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training took 0.19 seconds for 10 images\n",
      "Best cross-validation score: 0.53\n",
      "Test set score: 0.40\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 0.01, 'svc__gamma': 0.01}\n",
      "\n",
      "Model training took 1.61 seconds for 100 images\n",
      "Best cross-validation score: 0.61\n",
      "Test set score: 0.58\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n",
      "Model training took 30.19 seconds for 500 images\n",
      "Best cross-validation score: 0.58\n",
      "Test set score: 0.55\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 2, 'svc__gamma': 0.1}\n",
      "\n",
      "Model training took 110.19 seconds for 1000 images\n",
      "Best cross-validation score: 0.61\n",
      "Test set score: 0.61\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n",
      "Model training took 2973.79 seconds for 5000 images\n",
      "Best cross-validation score: 0.63\n",
      "Test set score: 0.65\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Nmax_values = [10, 100, 500, 1000] # removed , 5000, 12500 because they takemuch longer and the results are not any better\n",
    "\n",
    "pipe = Pipeline([('Preprocessing', MinMaxScaler()), ('svc', SVC())])\n",
    "\n",
    "param_grid = {'Preprocessing': [MinMaxScaler()],\n",
    "              'svc__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "              'svc__gamma':[0.0001, 0.001, 0.01, 0.1]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=3)\n",
    "\n",
    "for Nmax in Nmax_values:\n",
    "    Y_cats = np.array(Nmax * [1])\n",
    "    Y_dogs = np.array(Nmax * [0])\n",
    "    X_cvd = np.vstack([cats_features_2[:Nmax],dogs_features_2[:Nmax]])\n",
    "    Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "    start = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Model training took %.2f seconds for %d images\"\n",
    "      % ((time() - start), Nmax))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "    print(\"Best parameters: {}\\n\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 (5 points):\n",
    "\n",
    "Using the best network. Train a machine learning model able to predic COVID-19 from chest X-Ray images. Use the data from https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset. \n",
    "\n",
    "Present and discuss your best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: alextouvras\n",
      "Your Kaggle Key: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/1.19G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading coronahack-chest-xraydataset.zip to ./coronahack-chest-xraydataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.19G/1.19G [00:15<00:00, 83.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/praveengovi/coronahack-chest-xraydataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mypath = join(os.getcwd(),'coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train')\n",
    "\n",
    "all_imgs = [join(mypath,f) for f in listdir(mypath)]\n",
    "\n",
    "metadata =  pd.read_csv(\"coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X_ray_image_name</th>\n",
       "      <th>Label</th>\n",
       "      <th>Dataset_type</th>\n",
       "      <th>Label_2_Virus_category</th>\n",
       "      <th>Label_1_Virus_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>IM-0128-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>No Virus</td>\n",
       "      <td>No Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>IM-0127-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>No Virus</td>\n",
       "      <td>No Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IM-0125-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>No Virus</td>\n",
       "      <td>No Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>IM-0122-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>No Virus</td>\n",
       "      <td>No Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>IM-0119-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>No Virus</td>\n",
       "      <td>No Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>5304</td>\n",
       "      <td>1-s2.0-S0929664620300449-gr2_lrg-c.jpg</td>\n",
       "      <td>Pnemonia</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>5305</td>\n",
       "      <td>1-s2.0-S0929664620300449-gr2_lrg-b.jpg</td>\n",
       "      <td>Pnemonia</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>5306</td>\n",
       "      <td>1-s2.0-S0929664620300449-gr2_lrg-a.jpg</td>\n",
       "      <td>Pnemonia</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284</th>\n",
       "      <td>5307</td>\n",
       "      <td>1-s2.0-S0140673620303706-fx1_lrg.jpg</td>\n",
       "      <td>Pnemonia</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>5308</td>\n",
       "      <td>01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg</td>\n",
       "      <td>Pnemonia</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5286 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                           X_ray_image_name     Label  \\\n",
       "0              0                          IM-0128-0001.jpeg    Normal   \n",
       "1              1                          IM-0127-0001.jpeg    Normal   \n",
       "2              2                          IM-0125-0001.jpeg    Normal   \n",
       "3              3                          IM-0122-0001.jpeg    Normal   \n",
       "4              4                          IM-0119-0001.jpeg    Normal   \n",
       "...          ...                                        ...       ...   \n",
       "5281        5304     1-s2.0-S0929664620300449-gr2_lrg-c.jpg  Pnemonia   \n",
       "5282        5305     1-s2.0-S0929664620300449-gr2_lrg-b.jpg  Pnemonia   \n",
       "5283        5306     1-s2.0-S0929664620300449-gr2_lrg-a.jpg  Pnemonia   \n",
       "5284        5307       1-s2.0-S0140673620303706-fx1_lrg.jpg  Pnemonia   \n",
       "5285        5308  01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg  Pnemonia   \n",
       "\n",
       "     Dataset_type Label_2_Virus_category Label_1_Virus_category  \n",
       "0           TRAIN               No Virus               No Virus  \n",
       "1           TRAIN               No Virus               No Virus  \n",
       "2           TRAIN               No Virus               No Virus  \n",
       "3           TRAIN               No Virus               No Virus  \n",
       "4           TRAIN               No Virus               No Virus  \n",
       "...           ...                    ...                    ...  \n",
       "5281        TRAIN               COVID-19                  Virus  \n",
       "5282        TRAIN               COVID-19                  Virus  \n",
       "5283        TRAIN               COVID-19                  Virus  \n",
       "5284        TRAIN               COVID-19                  Virus  \n",
       "5285        TRAIN               COVID-19                  Virus  \n",
       "\n",
       "[5286 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = metadata[metadata.Dataset_type != 'TEST']\n",
    "metadata = metadata.fillna('No Virus')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mypath = join(os.getcwd(),'coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train')\n",
    "\n",
    "covid_imgs = metadata[\"X_ray_image_name\"][metadata[\"Label_2_Virus_category\"] == \"COVID-19\"]\n",
    "no_covid_imgs = metadata[\"X_ray_image_name\"][metadata[\"Label_2_Virus_category\"] != \"COVID-19\"]\n",
    "\n",
    "covid_imgs = [join(mypath,f) for f in covid_imgs ]\n",
    "no_covid_imgs = [join(mypath,f) for f in no_covid_imgs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images with covid: 58 and no covid: 5228\n"
     ]
    }
   ],
   "source": [
    "print(\"Images with covid: {} and no covid: {}\".format(len(covid_imgs),len(no_covid_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='https://github.com/miaow1988/SqueezeNet_v1.2'\n",
    "[mx.test_utils.download(path+'blob/master/model-symbol.json'),\n",
    " mx.test_utils.download(path+'blob/master/model-0000.params')]\n",
    " #mx.test_utils.download(path+'synset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('model', 0)\n",
    "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "# with open('synset.txt', 'r') as f:\n",
    "#    labels = [l.rstrip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_sym = all_layers['flatten0_output']\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features of all images, this might take a while\n",
    "covid_features = [get_features(get_image(img)).ravel() for img in covid_imgs]\n",
    "no_covid_features = [get_features(get_image(img)).ravel() for img in no_covid_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training took 0.57 seconds for 58 images\n",
      "Best cross-validation score: 0.98\n",
      "Test set score: 0.93\n",
      "Best parameters: {'Preprocessing': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svc__C': 10, 'svc__gamma': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Nmax_values = [58]\n",
    "\n",
    "pipe = Pipeline([('Preprocessing', MinMaxScaler()), ('svc', SVC())])\n",
    "\n",
    "param_grid = {'Preprocessing': [MinMaxScaler()],\n",
    "              'svc__C': [0.01, 0.1, 1, 2, 5, 10],\n",
    "              'svc__gamma':[0.0001, 0.001, 0.01, 0.1]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=3)\n",
    "\n",
    "for Nmax in Nmax_values:\n",
    "    Y_covid = np.array(Nmax * [1])\n",
    "    Y_no_covid = np.array(Nmax * [0])\n",
    "    X_cvd = np.vstack([covid_features[:Nmax],no_covid_features[:Nmax]])\n",
    "    Y_cvd = np.vstack([Y_covid,Y_no_covid]).ravel()\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)\n",
    "    start = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Model training took %.2f seconds for %d images\"\n",
    "      % ((time() - start), Nmax))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "    print(\"Best parameters: {}\\n\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_covid = len(covid_features[1])\n",
    "count_no_covid = len(no_covid_features[1])\n",
    "covid_features_over = covid_features.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.target.value_counts())\n",
    "\n",
    "df_test_over.target.value_counts().plot(kind='bar', title='Count (target)',color = color);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(covid_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
